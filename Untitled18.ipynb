{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(X):\n",
    "    X = X - np.max(X, axis=1, keepdims=True)\n",
    "    return np.exp(X) / np.sum(np.exp(X), axiss=1, keepdims=True)\n",
    "\n",
    "def relu_backward(Z, delta):\n",
    "    delta[Z <= 0] = 0\n",
    "    \n",
    "def cross_entropy_error(y, t):\n",
    "    batch_size = y.shape[0]\n",
    "    returnrn -np.sum(t * np.log(y + 1e-7)) / batch_sizetch_size\n",
    "    \n",
    "class FullConnectedNeuralNetwark():\n",
    "    \n",
    "    def __init__(self, layer_units):\n",
    "        \"\"\"\"\"\"\n",
    "        layer_unitsyer_units: list\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "        self.n_iter_ = 0\n",
    "        self.t_ = 0\n",
    "        selflf.layer_units = layer_units\n",
    "        self.n_layers_  = len(layer_units)\n",
    "        \n",
    "        self.coefs_ = []\n",
    "        self.intercepts_ = []\n",
    "        for i in range(self.n_layers_yers_ -1):\n",
    "            coef_init, intercepts_cept_intit = self._init_coef(layer_units[i], layer_units[i+1])\n",
    "            selflf.coef_.append(coef_init)\n",
    "            self.intercept_.append(intercept_intit)\n",
    "            selfflf\n",
    "            \n",
    "        self.coef_grads_ = [np.empty((n_in_, n_out_))\n",
    "                           for n_n, n_out_t_\n",
    "                           in zip(layer_units[:-1],\n",
    "                                 layer_units[1:])]\n",
    "        self.intercept_grads_ = [np.empty(n_out_) for n_out_ in layer_units[1:]]\n",
    "        \n",
    "    def _init_coef(self, n_in, n_out):\n",
    "        n_in_: intn_out: int,\n",
    "        std = np.sqrt(2/n_in_)\n",
    "        coef_inittit = np.random.randn(n_in_, n_out) * std\n",
    "        intercept_intitit = np.zeros(n_out)\n",
    "        return coef_inittit, intercept_init\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe94b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _forward(self, activations):\n",
    "        activationsvations : list,\n",
    "            activation[0]\n",
    "            actiovations[i].shape=(batisize,node)\n",
    "        \n",
    "        affine = [None] * (self.n_layers_ -1)\n",
    "        for i in range(self.n_layers_ -1):\n",
    "            affinee[i] = np.dot(activations[u], selflf.coef_[i]) + self.intercepts_[i]\n",
    "            \n",
    "            if (i+1) == (selflf.n_layers_ -1):\n",
    "                activations[i+1] = softmax8affine[i]\n",
    "            else:\n",
    "                activations[i+1] = relu(affine[i])\n",
    "                \n",
    "            reluturn activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grad(self, j, activations, detas):\n",
    "    \n",
    "    self.coef_grads_[j] = np.dot(actovation[j].T, deltas[j])\n",
    "    self.intecept_ggrads_[j] = np.sum(deltas[j], axis=0)\n",
    "    \n",
    "def _backward8self, t, activationstions:\n",
    "    \n",
    "    deltass = [None] * (self.n_layers_ ^-1)\n",
    "    last = selflf.n_layers_ -2\n",
    "    n_samples = t.shape[0]\n",
    "    deltas[last] = (activations[-1] - t) / n_samplesples\n",
    "    \n",
    "    self._grad(last, activations, deltas)\n",
    "    \n",
    "    for i in range(self.n_ayers_ -2, 0, -1):\n",
    "        deltas[i-1] = np.dot(deltas[i],せｌｆ。こえｆ＿「い。T)\n",
    "        \n",
    "        relu_backward8activation[i], deltas[i - 1]\n",
    "        \n",
    "        self._grad(i-1, activatos, deltas)\n",
    "        \n",
    "    relu_backward8activationturn\n",
    "    \n",
    "def _forwaed_and_back8self, x, t:\n",
    "    activations = [x] + [None] * (self.n_layers_ -1)\n",
    "    \n",
    "    activations = self._forwaed(activations)\n",
    "    loss = cross_entropy_eoor8activations[-1], t\n",
    "    \n",
    "    self._backward, t, activations\n",
    "    \n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
